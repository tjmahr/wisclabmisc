% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/impute-staged.R
\name{impute_values_by_length}
\alias{impute_values_by_length}
\title{Staged imputation}
\usage{
impute_values_by_length(
  data,
  var_y,
  var_length,
  id_cols = NULL,
  include_max_length = FALSE,
  data_train = NULL
)
}
\arguments{
\item{data}{dataframe in which to impute missing value}

\item{var_y}{bare name of the response variable for imputation}

\item{var_length}{bare name of the length variable}

\item{id_cols}{a selection of variable names that uniquely identify each
group of related observations. For example, \code{c(child_id, age_months)}.}

\item{include_max_length}{whether to use the maximum length value as a
predictor in the imputation models. Defaults to \code{FALSE}.}

\item{data_train}{(optional) dataframe used to train the imputation models.
For example, we might have data from a reference group of children in
\code{data_train} but a clinical population in \code{data}. If omitted, the dataframe
in \code{data} is used to train the models.}
}
\value{
a dataframe with the additional columns \verb{\{var_y\}_imputed} (the
imputed value), \verb{.max_\{var_length\}} with the highest value of \code{var_length}
with observed data, and \verb{\{var_y\}_imputation} for labeling whether
observations were \code{"imputed"} or \code{"observed"}.
}
\description{
Staged imputation
}
\section{Background}{
In Hustad and colleagues (2020), we modeled intelligibility data in young
children's speech. Children would hear and utterance and then they would
repeat it. The utterances started at 2 words in length, then increased to 3
words in length, and so on in batches, all the way to 7 words in length.
There was a problem, however: Not all of the children could produce
utterances at every length. Specifically, if a child could not reliably
produced 5 utterances of a given length length, the task was halted. So given
the nature of the task, if a child had produced 5-word utterances, they also
produced 2--4 words as well.

The length of the utterance probably influenced the outcome variable: Longer
utterances have more words that might help a listener understand the
sentence, for example. Therefore, it did not seem appropriate to ignore the
missing values. We used the following two-step procedure (see the
\href{https://doi.org/10.23641/asha.12330956.v1}{Supplemental Materials} for more
detail):
\enumerate{
\item impute the missing values at each utterance length using values from
shorter lengths, and do the imputation in stages , so that an imputed value
for length \emph{l} can be used a predictor for \emph{l} + 1.
\item weight each utterance length by the probability of it being produced for a
child at a given age and take the weighted average of the outcome variable
across all length.
}

Our goal for the data preparation was to produce a single number
intelligibility score, which this final weighted average provides such a
number. Moreover, missing data is not ignored, but implausible data (like the
longest utterances at the youngest ages) is downweighted.
\subsection{The Implementation}{

The original code consisting of some code to reshape the data into a wide
format, followed by a series of linear models trained on the \emph{observed} data,

\if{html}{\out{<div class="sourceCode r">}}\preformatted{fit_imputation_models <- function(data) \{
  list(
    m_7 = lm(y_7 ~ y_1 + y_2 + y_3 + y_4 + y_5 + y_6, data),
    m_6 = lm(y_6 ~ y_1 + y_2 + y_3 + y_4 + y_5 + length_longest, data),
    m_5 = lm(y_5 ~ y_1 + y_2 + y_3 + y_4 + length_longest, data),
    m_4 = lm(y_4 ~ y_1 + y_2 + y_3 + length_longest, data),
    m_3 = lm(y_3 ~ y_1 + y_2 + length_longest, data)
  )
\}
}\if{html}{\out{</div>}}

some code to predict the responses for missing values,

\if{html}{\out{<div class="sourceCode r">}}\preformatted{data_imputed <- data_wide \%>\%
  mutate(
    y_3 = ifelse(is.na(y_3), predict(models$m_3, .), y_3)
  ) \%>\%
  mutate(
    y_4 = ifelse(is.na(y_4), predict(models$m_4, .), y_4)
  ) \%>\%
  mutate(
    y_5 = ifelse(is.na(y_5), predict(models$m_5, .), y_5)
  ) \%>\%
  mutate(
    y_6 = ifelse(is.na(y_6), predict(models$m_6, .), y_6)
  ) \%>\%
  mutate(
    y_7 = ifelse(is.na(y_7), predict(models$m_7, .), y_7)
  )

## later on, without the `\%>\%` pipe and `.` variable

data_imputed <- data_wide |>
  mutate(
    y_3 = ifelse(is.na(y_3), predict(models$m_3, pick(everything())), y_3)
  ) |>
  mutate(
    y_4 = ifelse(is.na(y_4), predict(models$m_4, pick(everything())), y_4)
  ) |>
  mutate(
    y_5 = ifelse(is.na(y_5), predict(models$m_5, pick(everything())), y_5)
  ) |>
  mutate(
    y_6 = ifelse(is.na(y_6), predict(models$m_6, pick(everything())), y_6)
  ) |>
  mutate(
    y_7 = ifelse(is.na(y_7), predict(models$m_7, pick(everything())), y_7)
  )
}\if{html}{\out{</div>}}

and finally some code to reshape back to a long format.

In the original implementation, the number of models and imputation stages
were hard-coded. For the package implementation, the number of models is
figured out from the data, so the iteration in the above lines is replaced
by loops.
}

\subsection{Other notes}{

Remark about \code{data} and \code{data_train}: One might ask, \emph{why shouldn't some
children help train the data imputation models?} Let's consider a
norm-referenced standardized testing scenario: We have a new participant
(observations in \code{data}), and we want to know how they compare to their age
peers (participants in \code{data_train}). By separating out \code{data_train} and
fixing it to a reference group, we can apply the same adjustment/imputation
procedure to all new participants.
}
}

\examples{
fake_data <- tibble::tibble(
  child = c(
    "a", "a", "a", "a", "a",
    "b", "b", "b", "b", "b",
    "c", "c", "c", "c", "c",
    "e", "e", "e", "e", "e",
    "f", "f", "f", "f", "f",
    "g", "g", "g", "g", "g",
    "h", "h", "h", "h", "h",
    "i", "i", "i", "i", "i"
  ),
  level = c(1:5, 1:5, 1:5, 1:5, 1:5, 1:5, 1:5, 1:5),
  x = c(
    c(100, 110, 120, 130, 150) + c(-8, -5, 0, NA, NA),
    c(100, 110, 120, 130, 150) + c(6, 6, 4, NA, NA),
    c(100, 110, 120, 130, 150) + c(-5, -5, -2, 2, NA),
    c(100, 110, 120, 130, 150) + rbinom(5, 12, .5) - 6,
    c(100, 110, 120, 130, 150) + rbinom(5, 12, .5) - 6,
    c(100, 110, 120, 130, 150) + rbinom(5, 12, .5) - 6,
    c(100, 110, 120, 130, 150) + rbinom(5, 12, .5) - 6,
    c(100, 110, 120, 130, 150) + rbinom(5, 12, .5) - 6
  )
)
data_imputed <- impute_values_by_length(fake_data, x, level, id_cols = c(child))

if (requireNamespace("ggplot2")) {
  library(ggplot2)
  ggplot(data_imputed) +
    aes(x = level, y = x_imputed) +
    geom_line(aes(group = child)) +
    geom_point(aes(color = x_imputation))
}
}
\references{
Hustad, K. C., Mahr, T., Natzke, P. E. M., & Rathouz, P. J.
(2020). Development of Speech Intelligibility Between 30 and 47 Months in
Typically Developing Children: A Cross-Sectional Study of Growth. \emph{Journal
of Speech, Language, and Hearing Research}, \emph{63}(6), 1675â€“1687.
https://doi.org/10.1044/2020_JSLHR-20-00008

Hustad, K. C., Mahr, T., Natzke, P. E. M., & J. Rathouz, P. (2020).
Supplemental Material S1 (Hustad et al., 2020). ASHA journals.
https://doi.org/10.23641/asha.12330956.v1
}
